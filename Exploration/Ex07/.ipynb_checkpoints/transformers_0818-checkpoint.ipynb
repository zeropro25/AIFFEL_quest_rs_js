{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f9ccf9-7e2c-49fb-b3d4-9901ce5b8c6e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd71367b-8aed-4627-815a-bbf6bb311615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d701ef9-d9a8-4ab7-b188-bb8a864244b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b4eb65-afcf-4878-a9f7-f747c01a0c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/transformer_chatbot/data\n"
     ]
    }
   ],
   "source": [
    "cd ~/work/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ac50fe-8fa7-4080-9b81-da08078f8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d829e0-b22e-4157-b991-2ed71776d322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()       # 앞부분 5행 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf42aa1b-a2c1-4714-9e9a-176f89259f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape        # (행 개수, 열 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b248a39c-c069-4cc5-93bf-dadaa5675413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Q', 'A', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns      # 컬럼명 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9d35a6-1ab5-4a94-885b-78f6125f71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()       # 컬럼 정보, 데이터 타입, 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f63757e-083b-41a4-ae46-fde6baff75c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d3913-55f4-414b-b620-2c41384307fc",
   "metadata": {},
   "source": [
    "데이터 다운로드 깃허브: https://github.com/songys/Chatbot_data/blob/master/README.md\n",
    "\n",
    "Readme를 읽어보니, 라벨의 의미는 다음과 같다.\n",
    "\n",
    "- 일반다반사: 0\n",
    "- 이별(부정): 1\n",
    "- 사랑(긍정): 2\n",
    "\n",
    "개수가 많지는 않아서 전체를 모두 사용해도 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b462d8d-03ef-4d58-8d14-bcf8b03138bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5290\n",
       "1    3570\n",
       "2    2963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()  # 컬럼 값 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729e8373-8c33-45d5-8457-ba3720b59653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q         True\n",
       "A         True\n",
       "label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda col: col.astype(str).str.contains('[a-zA-Z]').any())\n",
    "# 영어가 있는 지 확인\n",
    "# 근데 Head에도 PPL이라는 영어가 있었다. 영어를 고려해서 전처리해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835fef9-bda5-4155-a611-af01c2c062b7",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "\n",
    "- preprocess_sentence: 공백, 특수문자, 구두점 공백 삽입\n",
    "- Q와 A에 전처리 적용하고 Pair 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5451db6-cf91-42c0-8703-fc872d8efe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 문장 앞 뒤의 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"12시가 땡!\" => \"12시가 땡 !\"와 같이\n",
    "  # 땡과 느낌표 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "  # 연속된 공백을 하나의 공백으로 축소\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  #한글, 영어, 숫자, 구두점만 남기고 나머지 제고\n",
    "  sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip() # 앞 뒤 공백 다시 제거\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "556cc9da-ee1f-4085-90fb-33e816285a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡 !\n",
      "ppl 심하네 ? ?\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_sentence(\"12시 땡!\"))   # 결과: \"12시 땡 !\"\n",
    "print(preprocess_sentence(\"PPL 심하네??\")) # 결과: \"ppl 심하네 ??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c52eb23-f3fb-4025-b40c-999b6caab02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "csv_path = Path.home() / \"work/transformer_chatbot/data/ChatbotData.csv\"\n",
    "\n",
    "# Q/A 각각 전처리 적용\n",
    "# astype(str)은 결측값이나 숫자가 있어도 str로 변환\n",
    "df['Q'] = df['Q'].astype(str).apply(preprocess_sentence)\n",
    "df['A'] = df['A'].astype(str).apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c755cea-237f-40c1-bcb9-f93f66ab959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡 !</td>\n",
       "      <td>하루가 또 가네요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sd카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sd카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sns 맞팔 왜 안하지</td>\n",
       "      <td>잘 모르고 있을 수도 있어요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                    A  label\n",
       "0                  12시 땡 !          하루가 또 가네요 .      0\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다 .      0\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
       "4                  ppl 심하네          눈살이 찌푸려지죠 .      0\n",
       "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요 .      0\n",
       "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요 .      0\n",
       "7             sns 맞팔 왜 안하지    잘 모르고 있을 수도 있어요 .      0\n",
       "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요 .      0\n",
       "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요 .      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)   # 앞 10행 확인해서 잘 적용됐는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c00ecc3b-2e1f-46d9-ae0b-602ce7760cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈 Q 개수: 0\n",
      "빈 A 개수: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"빈 Q 개수:\", (df['Q'].str.len() == 0).sum())\n",
    "print(\"빈 A 개수:\", (df['A'].str.len() == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3e45ee-ca73-43c2-a330-50ee65ebafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('12시 땡 !', '하루가 또 가네요 .'), ('1지망 학교 떨어졌어', '위로해 드립니다 .'), ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠 .'), ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠 .'), ('ppl 심하네', '눈살이 찌푸려지죠 .')]\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습용 pairs 생성\n",
    "pairs = list(zip(df['Q'], df['A']))\n",
    "print(pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142db48-01cc-485a-b8a6-e68c7cd56b5f",
   "metadata": {},
   "source": [
    "## Tokenizer 학습\n",
    "\n",
    "1. pair를 clean_corpus.txt로 저장하고\n",
    "2. sentencePeice trainer를 이용해서 토크나이저 학습: corpus를 기반으로 새로운 vocab을 만든다.\n",
    "3. 토크나이저가 담길 model, vocab 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f00a21-e9a3-4fbd-af7a-625e58529fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair를 txt 파일로 저장\n",
    "corpus_file = \"clean_corpus.txt\"\n",
    "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "    for q, a in pairs:\n",
    "        f.write(q + \"\\n\")\n",
    "        f.write(a + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf1808a9-9e29-4385-bb09-92d016fd8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: clean_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_cornell\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: clean_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23646 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=369459\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1225\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23646 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 20648\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13942 min_freq=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1055 size=20 all=16544 active=1772 piece=▁거예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=776 size=40 all=17277 active=2505 piece=▁여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=619 size=60 all=17948 active=3176 piece=▁좋아하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=427 size=80 all=18555 active=3783 piece=▁모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=358 size=100 all=19286 active=4514 piece=▁전\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=357 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=120 all=19722 active=1402 piece=▁뭐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=140 all=20320 active=2000 piece=▁소\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=227 size=160 all=20745 active=2425 piece=▁비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=180 all=21106 active=2786 piece=▁행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=200 all=21475 active=3155 piece=▁관\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=188 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=172 size=220 all=21830 active=1422 piece=▁재\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=240 all=22157 active=1749 piece=▁데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=260 all=22480 active=2072 piece=▁자꾸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=280 all=22863 active=2455 piece=▁고백\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=300 all=23218 active=2810 piece=▁먼저\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=130 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=320 all=23552 active=1491 piece=▁헤어진지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=340 all=23883 active=1822 piece=▁버\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=360 all=24101 active=2040 piece=▁돈\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=380 all=24428 active=2367 piece=▁하루\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=400 all=24825 active=2764 piece=▁함\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=420 all=25109 active=1524 piece=▁남자친구\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=440 all=25330 active=1745 piece=다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=460 all=25586 active=2001 piece=▁사람은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=480 all=25827 active=2242 piece=하네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=500 all=26100 active=2515 piece=▁설\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=520 all=26325 active=1518 piece=▁어떨까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=540 all=26553 active=1746 piece=▁해도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=560 all=26828 active=2021 piece=▁그만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=580 all=26994 active=2187 piece=▁휴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=600 all=27181 active=2374 piece=▁항상\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=620 all=27347 active=1526 piece=▁문제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=640 all=27613 active=1792 piece=▁상황\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=660 all=27861 active=2040 piece=▁개\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=680 all=28068 active=2247 piece=▁가보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=700 all=28190 active=2369 piece=▁충분히\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=720 all=28342 active=1562 piece=▁열심히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=740 all=28482 active=1702 piece=▁종\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=760 all=28645 active=1865 piece=▁만남\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=780 all=28773 active=1993 piece=으니까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=800 all=28918 active=2138 piece=▁부모님\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=820 all=29024 active=1543 piece=▁헤어지고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=840 all=29157 active=1676 piece=더니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=860 all=29298 active=1817 piece=▁살아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=880 all=29392 active=1911 piece=▁잊혀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=900 all=29510 active=2029 piece=▁재밌\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=920 all=29653 active=1604 piece=▁소개팅\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=940 all=29769 active=1720 piece=▁끊\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=960 all=29964 active=1915 piece=▁잘하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=980 all=30116 active=2067 piece=▁정도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1000 all=30262 active=2213 piece=▁붙잡\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=1020 all=30386 active=1626 piece=같아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1040 all=30526 active=1766 piece=▁익\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1060 all=30661 active=1901 piece=드릴게요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1080 all=30810 active=2050 piece=▁힘내세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1100 all=30916 active=2156 piece=▁아닌데\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1120 all=31008 active=1638 piece=▁무엇\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1140 all=31099 active=1729 piece=▁관리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1160 all=31198 active=1828 piece=어야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1180 all=31312 active=1942 piece=이었을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1200 all=31421 active=2051 piece=지고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1220 all=31489 active=1625 piece=▁지금은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1240 all=31575 active=1711 piece=▁부러\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1260 all=31612 active=1748 piece=▁필요해요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1280 all=31705 active=1841 piece=▁부분\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1300 all=31789 active=1925 piece=▁남편이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1320 all=31845 active=1646 piece=밖에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1340 all=31986 active=1787 piece=▁안나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1360 all=32054 active=1855 piece=▁해봐요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1380 all=32134 active=1935 piece=▁맞춰\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1400 all=32219 active=2020 piece=▁생각만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1420 all=32266 active=1657 piece=▁되네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1440 all=32376 active=1767 piece=줬으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1460 all=32437 active=1828 piece=▁가야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1480 all=32486 active=1877 piece=▁조언\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1500 all=32549 active=1940 piece=더라고요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1520 all=32665 active=1735 piece=한게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1540 all=32757 active=1827 piece=▁태어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1560 all=32801 active=1871 piece=▁받아들이는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1580 all=32896 active=1966 piece=식을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1600 all=33008 active=2078 piece=▁적응\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1620 all=33052 active=1687 piece=▁잊어버\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1640 all=33061 active=1696 piece=시켜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1660 all=33184 active=1819 piece=▁어색\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1680 all=33274 active=1909 piece=▁그사람\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1700 all=33287 active=1922 piece=▁각\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1720 all=33408 active=1784 piece=었다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1740 all=33502 active=1878 piece=▁안타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1760 all=33560 active=1936 piece=▁성격이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1780 all=33574 active=1950 piece=▁판\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1800 all=33715 active=2091 piece=▁끝은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1820 all=33771 active=1742 piece=▁일도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1840 all=33823 active=1794 piece=▁연습을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1860 all=33863 active=1834 piece=냐고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1880 all=33969 active=1940 piece=▁다니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1900 all=34023 active=1994 piece=▁없애\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1920 all=34101 active=1773 piece=▁가자고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1940 all=34117 active=1789 piece=▁사랑한다고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1960 all=34174 active=1846 piece=어서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1980 all=34264 active=1936 piece=▁되면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2000 all=34341 active=2013 piece=▁있지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2020 all=34380 active=1757 piece=▁쉬세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2040 all=34386 active=1763 piece=▁연락하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2060 all=34429 active=1806 piece=간이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2080 all=34563 active=1940 piece=▁내는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2100 all=34603 active=1980 piece=▁조급\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2120 all=34634 active=1757 piece=▁상황이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2140 all=34626 active=1749 piece=▁썸남한테\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2160 all=34612 active=1735 piece=▁잊어버리세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2180 all=34702 active=1825 piece=어진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2200 all=34825 active=1948 piece=▁남의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2220 all=34868 active=1785 piece=▁선톡\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2240 all=34939 active=1856 piece=▁줘도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2260 all=34997 active=1914 piece=▁기념일\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2280 all=35005 active=1922 piece=▁연애를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2300 all=35021 active=1938 piece=▁남자들은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2320 all=35016 active=1747 piece=▁헤어졌는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2340 all=35076 active=1807 piece=렸어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2360 all=35150 active=1881 piece=▁다들\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2380 all=35178 active=1909 piece=▁신고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2400 all=35222 active=1953 piece=▁편한\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2420 all=35253 active=1793 piece=▁만난지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2440 all=35248 active=1788 piece=▁운동을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2460 all=35231 active=1771 piece=▁안됐는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2480 all=35216 active=1756 piece=▁정리하는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2500 all=35266 active=1806 piece=가봐\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2520 all=35362 active=1852 piece=하러\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2540 all=35398 active=1888 piece=▁달달\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2560 all=35430 active=1920 piece=▁설렘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2580 all=35477 active=1967 piece=▁전공\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2600 all=35546 active=2036 piece=하지만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2620 all=35554 active=1775 piece=▁부족한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2640 all=35545 active=1766 piece=▁집들이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2660 all=35553 active=1774 piece=▁일이네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2680 all=35538 active=1759 piece=▁김\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2700 all=35606 active=1827 piece=대폰\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2720 all=35686 active=1859 piece=하던\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2740 all=35725 active=1898 piece=▁마실\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2760 all=35761 active=1934 piece=▁부자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2780 all=35802 active=1975 piece=▁죽고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2800 all=35863 active=2036 piece=하다가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2820 all=35881 active=1804 piece=▁바쁘게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2840 all=35876 active=1799 piece=▁연애가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2860 all=35865 active=1788 piece=셔보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2880 all=35874 active=1797 piece=▁여자들은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2900 all=35862 active=1785 piece=▁지금이라도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2920 all=35902 active=1834 piece=거죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2940 all=35997 active=1929 piece=보내\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2960 all=36094 active=2026 piece=▁곁에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2980 all=36125 active=2057 piece=▁모른\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3000 all=36147 active=2079 piece=▁술마\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3020 all=36165 active=1821 piece=▁입을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3040 all=36207 active=1863 piece=르세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3060 all=36258 active=1914 piece=▁꽃다발\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3080 all=36259 active=1915 piece=▁보내는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3100 all=36248 active=1904 piece=▁위로봇\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3120 all=36244 active=1807 piece=▁차라리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3140 all=36236 active=1799 piece=▁마련이죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3160 all=36227 active=1790 piece=▁짝사랑은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3180 all=36220 active=1783 piece=▁마지막으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3200 all=36217 active=1780 piece=▁얻\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3220 all=36266 active=1854 piece=만은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3240 all=36342 active=1930 piece=활동\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3260 all=36364 active=1952 piece=▁다닐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3280 all=36397 active=1985 piece=▁반응\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3300 all=36434 active=2022 piece=▁시키\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3320 all=36471 active=1855 piece=▁이직\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3340 all=36492 active=1876 piece=▁쳐다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3360 all=36534 active=1918 piece=겼는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3380 all=36612 active=1996 piece=▁같아서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3400 all=36605 active=1989 piece=▁늘어요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3420 all=36597 active=1823 piece=▁뭐할까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3440 all=36588 active=1814 piece=▁아이돌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3460 all=36587 active=1813 piece=▁찾기를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3480 all=36600 active=1826 piece=▁고백하면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3500 all=36582 active=1808 piece=▁싫어하는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3520 all=36580 active=1828 piece=▁헤어지자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3540 all=36564 active=1812 piece=▁취해보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3560 all=36572 active=1820 piece=▁색\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3580 all=36633 active=1881 piece=년을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3600 all=36695 active=1943 piece=순간\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3620 all=36752 active=1886 piece=콜릿\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3640 all=36768 active=1902 piece=▁길어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3660 all=36781 active=1915 piece=▁동성\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3680 all=36805 active=1939 piece=▁사내\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3700 all=36822 active=1956 piece=▁어필\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3720 all=36835 active=1852 piece=▁종일\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3740 all=36864 active=1881 piece=▁했나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3760 all=36919 active=1936 piece=할거라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3780 all=36925 active=1942 piece=▁끝났네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3800 all=36910 active=1927 piece=▁말해도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3820 all=36909 active=1845 piece=▁상대가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3840 all=36898 active=1834 piece=▁앞두고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3860 all=36900 active=1836 piece=▁자세히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3880 all=36895 active=1831 piece=▁하려고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3900 all=36895 active=1831 piece=▁당연하죠\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3920 all=36880 active=1830 piece=▁신혼여행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3940 all=36870 active=1820 piece=▁카페에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3960 all=36858 active=1808 piece=▁만남이었길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3980 all=36842 active=1792 piece=▁풀어보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4000 all=36849 active=1799 piece=▁롱\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4020 all=36891 active=1883 piece=곰히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4040 all=36949 active=1941 piece=면증\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4060 all=37005 active=1997 piece=젯밤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4080 all=37053 active=2045 piece=화가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4100 all=37075 active=2067 piece=▁귀를\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4120 all=37096 active=1875 piece=▁대중\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4140 all=37111 active=1890 piece=▁며칠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4160 all=37129 active=1908 piece=▁성적\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4180 all=37142 active=1921 piece=▁썼어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4200 all=37155 active=1934 piece=▁왕따\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4220 all=37168 active=1866 piece=▁자취\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4240 all=37187 active=1885 piece=▁차갑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4260 all=37218 active=1916 piece=▁평온\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4280 all=37238 active=1936 piece=근차근\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4300 all=37290 active=1988 piece=적이고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4320 all=37317 active=1889 piece=▁것들이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4340 all=37305 active=1877 piece=▁나가기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4360 all=37293 active=1865 piece=▁떠보는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4380 all=37283 active=1855 piece=▁미래에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4400 all=37272 active=1844 piece=▁서로가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4420 all=37259 active=1851 piece=▁알았어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4440 all=37245 active=1837 piece=▁이해할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4460 all=37240 active=1832 piece=▁집착해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4480 all=37235 active=1827 piece=▁하거나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4500 all=37240 active=1832 piece=▁고민하게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4520 all=37227 active=1849 piece=▁만들려고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4540 all=37212 active=1834 piece=▁소개시켜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4560 all=37206 active=1828 piece=▁인정받고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4580 all=37194 active=1816 piece=▁학교에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4600 all=37182 active=1804 piece=▁사랑한다는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4620 all=37164 active=1841 piece=▁준비하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4640 all=37147 active=1824 piece=▁피곤한가봐요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4660 all=37159 active=1836 piece=▁씌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4680 all=37202 active=1879 piece=난거\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4700 all=37236 active=1913 piece=문이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4720 all=37293 active=1915 piece=오를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4740 all=37352 active=1974 piece=증을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4760 all=37382 active=2004 piece=▁거는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4780 all=37391 active=2013 piece=▁끓여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4800 all=37404 active=2026 piece=▁답은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4820 all=37396 active=1863 piece=▁모를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4840 all=37410 active=1877 piece=▁번씩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4860 all=37413 active=1880 piece=▁설렜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4880 all=37433 active=1900 piece=▁아마\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4900 all=37447 active=1914 piece=▁이모\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4920 all=37466 active=1890 piece=▁지낼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4940 all=37483 active=1907 piece=▁타다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4960 all=37507 active=1931 piece=끄러워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4980 all=37556 active=1980 piece=정적인\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5000 all=37572 active=1996 piece=▁공부할\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5020 all=37568 active=1874 piece=▁다르죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5040 all=37565 active=1871 piece=▁마셔도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5060 all=37557 active=1863 piece=▁못했던\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5080 all=37545 active=1851 piece=▁봤는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5100 all=37536 active=1842 piece=▁습관이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5120 all=37525 active=1866 piece=▁여행은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5140 all=37520 active=1861 piece=▁재밌다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5160 all=37508 active=1849 piece=▁찾아온\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5180 all=37499 active=1840 piece=▁한숨만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5200 all=37502 active=1843 piece=해야겠다\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5220 all=37502 active=1871 piece=▁도전하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5240 all=37487 active=1856 piece=▁보고싶네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5260 all=37472 active=1841 piece=▁아는데도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5280 all=37460 active=1829 piece=▁이어나가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5300 all=37446 active=1815 piece=▁좋았으면\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5320 all=37432 active=1859 piece=▁후회하기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5340 all=37420 active=1847 piece=▁맡겨보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5360 all=37402 active=1829 piece=▁잃어버렸어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5380 all=37388 active=1815 piece=▁좋아해줬으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5400 all=37404 active=1831 piece=▁민\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5420 all=37417 active=1882 piece=▁핫\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5440 all=37458 active=1923 piece=기에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5460 all=37491 active=1956 piece=력에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5480 all=37519 active=1984 piece=받을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5500 all=37561 active=2026 piece=양제\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5520 all=37599 active=1916 piece=조건\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5540 all=37640 active=1957 piece=하진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5560 all=37655 active=1972 piece=▁갠톡\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5580 all=37656 active=1973 piece=▁꼬박\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5600 all=37649 active=1966 piece=▁농구\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5620 all=37655 active=1886 piece=▁뒤에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5640 all=37649 active=1880 piece=▁맞아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5660 all=37657 active=1888 piece=▁믿지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5680 all=37671 active=1902 piece=▁봐주\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5700 all=37693 active=1924 piece=▁선풍\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5720 all=37708 active=1897 piece=▁안고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5740 all=37712 active=1901 piece=▁예상\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5760 all=37715 active=1904 piece=▁웨딩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5780 all=37727 active=1916 piece=▁잠들\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5800 all=37740 active=1929 piece=▁증명\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5820 all=37756 active=1902 piece=▁청춘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5840 all=37763 active=1909 piece=▁톡이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5860 all=37768 active=1914 piece=▁현타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5880 all=37783 active=1929 piece=렵니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5900 all=37816 active=1962 piece=하기로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5920 all=37844 active=1915 piece=▁가야돼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5940 all=37829 active=1900 piece=▁고시원\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5960 all=37814 active=1885 piece=▁기억은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5980 all=37805 active=1876 piece=▁내일을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6000 all=37791 active=1862 piece=▁되려고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6020 all=37781 active=1880 piece=▁레시피\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6040 all=37772 active=1871 piece=▁매력을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6060 all=37757 active=1856 piece=▁미련을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6080 all=37745 active=1844 piece=▁부족해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6100 all=37731 active=1830 piece=▁생각도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6120 all=37725 active=1881 piece=▁시선을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6140 all=37710 active=1866 piece=▁아이디\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6160 all=37702 active=1858 piece=▁어떡함\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6180 all=37689 active=1845 piece=▁예뻐질\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6200 all=37677 active=1833 piece=▁의심해\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6220 all=37670 active=1876 piece=▁있거나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6240 all=37664 active=1870 piece=▁접는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6260 all=37650 active=1856 piece=▁즐기는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6280 all=37634 active=1840 piece=▁커피는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6300 all=37617 active=1823 piece=▁함께도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6320 all=37607 active=1871 piece=드���거나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6340 all=37631 active=1895 piece=▁가리세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6360 all=37620 active=1884 piece=▁관심사에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6380 all=37604 active=1868 piece=▁낭만적인\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6400 all=37586 active=1850 piece=▁동생한테\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6420 all=37567 active=1860 piece=▁무한리필\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6440 all=37556 active=1849 piece=▁뿌린대로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6460 all=37539 active=1832 piece=▁쉬어가도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6480 all=37524 active=1817 piece=▁안타깝게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6500 all=37506 active=1799 piece=▁연애세포\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6520 all=37491 active=1860 piece=▁이왕이면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6540 all=37478 active=1847 piece=▁저마다의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6560 all=37460 active=1829 piece=▁친구인데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6580 all=37444 active=1813 piece=▁해봤는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6600 all=37435 active=1804 piece=▁가족들이랑\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6620 all=37419 active=1856 piece=▁놀러가세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6640 all=37399 active=1836 piece=▁받아들여야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6660 all=37381 active=1818 piece=▁세워보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6680 all=37361 active=1798 piece=▁연락하는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6700 all=37342 active=1779 piece=▁정리하세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6720 all=37325 active=1851 piece=▁표현해보는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6740 all=37307 active=1833 piece=▁되짚어보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6760 all=37287 active=1813 piece=▁필요해보여요\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: spm_cornell.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: spm_cornell.vocab\n"
     ]
    }
   ],
   "source": [
    "# sentencepiecetrainer 라이브러리를 이용해서 토크나이저 모델을 학습\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=corpus_file, #방금 만든 txt\n",
    "    model_prefix=\"spm_cornell\", # 만들어지는 파일의 접두사 설정\n",
    "    \n",
    "    vocab_size=8000, #만들 서브워드 토큰 개수\n",
    "    character_coverage=1.0, # 1.0이면 모든 문자 토큰화 (일본어나 중국어는 0.995로 희귀문자 희생시킴)\n",
    "    \n",
    "    model_type=\"bpe\", # byte pair encoding 방식의 알고리즘 선택\n",
    "    max_sentence_length=999999, # 학습할 때 문장 최대 길이\n",
    "\n",
    "    # 특별 토큰 id 번호 고정\n",
    "    bos_id=1,  # <s> (Beginning of Sentence) 설정\n",
    "    eos_id=2,  # </s> (End of Sentence) 설정\n",
    "    pad_id=0,  # Padding ID 설정\n",
    "    unk_id=3   # Unknown Token ID 설정\n",
    ")\n",
    "\n",
    "# 실행 결과:\n",
    "# -> spm_cornell.model, spm_cornell.vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d24f417-b948-49fd-8e77-4e7801ff9632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 문장: 3박4일 정도 놀러가고 싶다 !\n",
      "Tokenized: ['▁3', '박', '4', '일', '▁정도', '▁놀러가고', '▁싶다', '▁!']\n",
      "Encoded: [475, 7283, 7251, 6825, 983, 3491, 201, 108]\n",
      "Decoded: 3박4일 정도 놀러가고 싶다 !\n"
     ]
    }
   ],
   "source": [
    "# 학습시킨 토크나이저 모델 테스트: 전처리부터 토큰화, 인코딩, 디코딩이 잘 동작하는 지?!\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"spm_cornell.model\")\n",
    "\n",
    "# 테스트할 문장 준비\n",
    "sentence = \"3박4일 정도 놀러가고 싶다!\"\n",
    "\n",
    "sentence = preprocess_sentence(sentence)\n",
    "print(\"전처리 후의 문장:\", sentence)\n",
    "\n",
    "# 1. 토크나이징 (subword 단위로 분할)\n",
    "tokens = sp.encode(sentence, out_type=str)\n",
    "print(\"Tokenized:\", tokens)\n",
    "\n",
    "# 2. 인코딩 (서브워드를 정수 ID로 변환)\n",
    "encoded = sp.encode(sentence, out_type=int)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# 3. 디코딩 (정수 ID → 원본 문장 복원)\n",
    "decoded = sp.decode(encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd2b03-742c-49df-a24d-c2132b366a35",
   "metadata": {},
   "source": [
    "## 데이터셋 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81b24c1f-63e4-461a-8067-07dc7ce2aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CornellDataset(Dataset):\n",
    "    def __init__(self, pairs, sp, max_length= 40, add_special_tokens=True, use_sp_extra_opts=False):\n",
    "        \"\"\"\n",
    "        pairs: [(q_text, a_text), ...]\n",
    "        sp: sentencepiece processor\n",
    "        max_length: 고정 길이 (BOS/EOS 포함 길이 기준)\n",
    "        add_special_tokens: 수동으로 BOS/EOS 붙일지 여부\n",
    "        use_sp_extra_opts: sp.SetEncodeExtraOptions(\"bos:eos\") 를 이미 썼다면 True\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        # 특수 토큰 ID 가져오기\n",
    "        pad_id = sp.pad_id() if sp.pad_id() >= 0 else 0\n",
    "        bos_id = sp.bos_id() if sp.bos_id() >= 0 else 1\n",
    "        eos_id = sp.eos_id() if sp.eos_id() >= 0 else 2\n",
    "\n",
    "        # Pair를 돌면서 텐서로 변환\n",
    "        for q_text, a_text in pairs:\n",
    "            # 1) 토크나이즈\n",
    "            q_ids = sp.EncodeAsIds(q_text)\n",
    "            a_ids = sp.EncodeAsIds(a_text)\n",
    "\n",
    "            # 2) BOS/EOS 부착\n",
    "            if use_sp_extra_opts:\n",
    "                q_tokens = q_ids\n",
    "                a_tokens = a_ids\n",
    "            else:\n",
    "                if add_special_tokens:\n",
    "                    q_tokens = [bos_id] + q_ids + [eos_id]\n",
    "                    a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "                else:\n",
    "                    q_tokens = q_ids[:] # [:]는 복사를 의미. 원본 보존\n",
    "                    a_tokens = a_ids[:]\n",
    "\n",
    "            # 3) 길이 제한: 너무 길면 자른다.\n",
    "            if len(q_tokens) > self.max_length:\n",
    "                q_tokens = q_tokens[:self.max_length] \n",
    "            if len(a_tokens) > self.max_length:\n",
    "                a_tokens = a_tokens[:self.max_length]\n",
    "\n",
    "            # 4) 패딩: 부족한 길이는 PAD 토크으로 채워서 길이를 맞춤\n",
    "            q_len = len(q_tokens)\n",
    "            a_len = len(a_tokens)\n",
    "            if q_len < self.max_length:\n",
    "                q_tokens = q_tokens + [pad_id] * (self.max_length - q_len)\n",
    "            if a_len < self.max_length:\n",
    "                a_tokens = a_tokens + [pad_id] * (self.max_length - a_len)\n",
    "\n",
    "            # 5) 디코더 입력 교사 강요용 시프트\n",
    "            # dec_input: a[:-1], target: a[1:]\n",
    "            dec_input = a_tokens[:-1] # 디코더는 dec_input 보고 target을 예측\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            # 6) 마스크 생성(Transformer 용)\n",
    "            # enc_padding_mask: [B, 1, 1, L] 형태로 쓰는게 일반적이나,\n",
    "            # 여기서는 [L]을 반환하고, 모델에서 차원 확장하는 방식으로 가볍게 둡니다.\n",
    "            enc_padding_mask = [1 if tid != pad_id else 0 for tid in q_tokens]        # 1이면 유효토큰 keep, 0이면 차단하기 mask\n",
    "            dec_padding_mask = [1 if tid != pad_id else 0 for tid in dec_input]        # 디코더 키패딩용\n",
    "\n",
    "            # self.data에 딕셔너리로 저장\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target,\n",
    "                \"enc_padding_mask\": enc_padding_mask,\n",
    "                \"dec_padding_mask\": dec_padding_mask,\n",
    "            })\n",
    "\n",
    "    # 데이터셋 크기 반환\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # idx 번째 샘플을 텐서로 변환해서 반환\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data[idx]\n",
    "        return (\n",
    "            torch.tensor(s[\"enc_input\"], dtype=torch.long),\n",
    "            torch.tensor(s[\"dec_input\"], dtype=torch.long),\n",
    "            torch.tensor(s[\"target\"], dtype=torch.long),\n",
    "            torch.tensor(s[\"enc_padding_mask\"], dtype=torch.long),\n",
    "            torch.tensor(s[\"dec_padding_mask\"], dtype=torch.long),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ff374e1-a09d-4e21-bdca-04f6b71247e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 토큰 40으로 맞춰서 객체 생성\n",
    "dataset = CornellDataset(pairs, sp, max_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf3e8dc4-114e-4b54-99ac-93b997d49e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서 크기: torch.Size([40])\n",
      "tensor([   1, 5550, 6817, 3199,  108,    2,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n",
      "enc: 12시 땡 !\n",
      "tensor([   1, 4484,  214, 5918,    4,    2,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "dec_in: 하루가 또 가네요 .\n",
      "tensor([4484,  214, 5918,    4,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "tgt: 하루가 또 가네요 .\n"
     ]
    }
   ],
   "source": [
    "#샘플 확인\n",
    "pad_id = sp.pad_id() if sp.pad_id() >= 0 else 0\n",
    "bos_id = sp.bos_id() if sp.bos_id() >= 0 else 1\n",
    "eos_id = sp.eos_id() if sp.eos_id() >= 0 else 2\n",
    "\n",
    "# ID 시퀀스를 사람이 읽을 수 있는 문자열로 복원\n",
    "def trim_and_decode(sp, ids, pad_id=0, bos_id=1, eos_id=2):\n",
    "    if hasattr(ids, \"tolist\"):\n",
    "        ids = ids.tolist()\n",
    "    ids = [i for i in ids if i != pad_id]           # PAD 제거\n",
    "    if ids and ids[0] == bos_id: ids = ids[1:]      # BOS 제거\n",
    "    if eos_id in ids: ids = ids[:ids.index(eos_id)] # EOS까지\n",
    "    return sp.DecodeIds(ids) if hasattr(sp, \"DecodeIds\") else sp.decode_ids(ids)\n",
    "\n",
    "for enc_in, dec_in, tgt, enc_mask, dec_mask in dataset:\n",
    "    print(\"텐서 크기:\", enc_in.size())\n",
    "    print(enc_in)\n",
    "    print(\"enc:\", trim_and_decode(sp, enc_in, pad_id, bos_id, eos_id))\n",
    "    print(dec_in)\n",
    "    print(\"dec_in:\", trim_and_decode(sp, dec_in, pad_id, bos_id, eos_id))\n",
    "    print(tgt)\n",
    "    print(\"tgt:\", trim_and_decode(sp, tgt, pad_id, bos_id, eos_id))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f4756-70c4-4895-b2ef-5b30d7bfd957",
   "metadata": {},
   "source": [
    "## 데이터 로더 만들기\n",
    "\n",
    "지금 CornellDataset은 5개(enc_in, dec_in, tgt, enc_mask, dec_mask)를 반환함.\n",
    "\n",
    "-> 데이터 로더도 5개 텐서를 모두 받아줘야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3390a79-fdb5-4f9f-b328-8afa66462d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더는 CornellDataset에서 샘플을 꺼내서 배치 단위의 텐서 묶음으로 만든다.\n",
    "# 이 데이터로더를 학습 루프에 돌리면 된다.\n",
    "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52c5adbe-29c5-42f9-b0a8-136ab988e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_in     : torch.Size([32, 40])\n",
      "dec_in     : torch.Size([32, 39])\n",
      "tgt        : torch.Size([32, 39])\n",
      "enc_mask   : torch.Size([32, 40])\n",
      "dec_mask   : torch.Size([32, 39])\n"
     ]
    }
   ],
   "source": [
    "for enc_in, dec_in, tgt, enc_mask, dec_mask in dataloader:\n",
    "    print(\"enc_in     :\", enc_in.shape)      # [32, 40]\n",
    "    print(\"dec_in     :\", dec_in.shape)      # [32, 39]\n",
    "    print(\"tgt        :\", tgt.shape)         # [32, 39]\n",
    "    print(\"enc_mask   :\", enc_mask.shape)    # [32, 40]\n",
    "    print(\"dec_mask   :\", dec_mask.shape)    # [32, 39]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbab042-e3fe-413a-9a7c-8194b8d104a3",
   "metadata": {},
   "source": [
    "# 모델 수행을 위한 클래스 만들기\n",
    "\n",
    "- PE\n",
    "- 멀티헤드 어텐션\n",
    "- 스케일 닷 프로덕션\n",
    "- 인코더 레이어와 인코더\n",
    "- 디코더 레이어와 디코더\n",
    "- 패딩 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8ac620-7c3c-42be-9364-abd4a2cf0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35702fba-d97e-4185-9de0-1a10d6bc9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0223f6a-f696-4d9a-8e47-b8fcf52422a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c83c527a-032b-4e70-90ab-787fb1282055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd6af9aa-faca-46e2-8472-ffd16a9816ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "268bb208-69ba-4505-9d08-9ac0b7b58ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2fa9b1e-5a07-41ec-afb8-4a561d94aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # 실제 학습 시에는 최대 시퀀스 길이에 맞추어 쓰기도 함\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1190bdc9-58f8-4ac0-b77e-dce27e1eea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0cd0f68-f545-404b-b17d-34bd13e0f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "    # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "    # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "    # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915af264-f54e-4281-962f-bb6b52b755c2",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a262487-8d82-4e3e-b503-9d29a59a7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e607d89-931b-460d-89d6-e3d65c369cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-1): 2 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(8000, 256)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-1): 2 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=256, out_features=8000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 2     # 인코더/디코더 층 수\n",
    "D_MODEL = 256      # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512        # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.1      # 드롭아웃 비율\n",
    "VOCAB_SIZE = 8000 # 단어 집합 크기(예시)\n",
    "\n",
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecb0cd24-ca46-43dd-a68b-21db9791536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70058afe-5152-4939-a82e-548e771ff491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "def get_lr_lambda(d_model: int, warmup_steps: int = 4000, scale: float = 1.0):\n",
    "    \"\"\"\n",
    "    LambdaLR에 넣을 스케줄 함수 생성.\n",
    "    - d_model^{-0.5} * min(step^{-0.5}, step * warmup^{-1.5}) 형태\n",
    "    - scale로 전체 스케일 조절 가능\n",
    "    \"\"\"\n",
    "    def lr_lambda(step: int):\n",
    "        # LambdaLR은 step(=last_epoch)이 0부터 시작합니다.\n",
    "        step = max(1, step)\n",
    "        return scale * (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6472f2fc-ae1d-4c3c-84e8-babbb6f70823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습률 스케쥴 시각화\n",
    "# 하이퍼파라미터 설정\n",
    "d_model = 512\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n",
    "\n",
    "# 학습률 스케줄 시각화\n",
    "steps = np.arange(1, total_steps + 1)\n",
    "learning_rates = [get_lr_lambda(d_model, warmup_steps)(step) for step in steps]\n",
    "\n",
    "# 그래프 출력\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, learning_rates, label=\"Learning Rate\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Transformer Learning Rate Schedule\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a17e924-28f3-4c0c-ad8d-6e92b4f37d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "# 옵티마이저의 lr은 1.0로 두고, 실제 스케일은 lambda에서 모두 제어하는 방식\n",
    "optimizer = optim.Adam(model.parameters(), lr=1.0, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=4000)\n",
    ")\n",
    "\n",
    "# 정확도: PAD 제외\n",
    "def accuracy_function(logits, target, pad_id=0):\n",
    "    # logits: [B, L, V], target: [B, L]\n",
    "    with torch.no_grad():\n",
    "        preds = logits.argmax(dim=-1)              # [B, L]\n",
    "        mask = (target != pad_id)                  # [B, L]\n",
    "        correct = ((preds == target) & mask).sum()\n",
    "        total = mask.sum().clamp_min(1)\n",
    "        return (correct.float() / total.float()).item()\n",
    "\n",
    "# 배치 안전 언패킹: (3개 or 5개 모두 지원)\n",
    "def unpack_batch(batch, device, pad_id=0):\n",
    "    if len(batch) == 3:\n",
    "        enc_in, dec_in, tgt = [t.to(device) for t in batch]\n",
    "        # 마스크는 여기서 즉석 생성\n",
    "        enc_mask = (enc_in != pad_id).long()\n",
    "        dec_mask = (dec_in != pad_id).long()\n",
    "    elif len(batch) == 5:\n",
    "        enc_in, dec_in, tgt, enc_mask, dec_mask = [t.to(device) for t in batch]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "    return enc_in, dec_in, tgt, enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d0a5af2-3286-470b-83d2-9edf10e3d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f8c0a-58d3-4018-a26b-e7844ebd6b2e",
   "metadata": {},
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a479ba9-2d6d-473d-bd01-d6bd1c1c9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "pad_id = sp.pad_id() if sp.pad_id() >= 0 else 0\n",
    "\n",
    "def train_step(model, batch, optimizer, loss_function, device, scheduler=None, grad_clip=1.0):\n",
    "    model.train()\n",
    "\n",
    "    # 배치 언패킹 (3개만 오거나 5개가 오거나 모두 처리)\n",
    "    if len(batch) == 5:\n",
    "        enc_in, dec_in, tgt, enc_mask, dec_mask = batch\n",
    "        enc_mask = enc_mask.bool()\n",
    "        dec_mask = dec_mask.bool()\n",
    "    elif len(batch) == 3:\n",
    "        enc_in, dec_in, tgt = batch\n",
    "        enc_mask = (enc_in != pad_id).bool()\n",
    "        dec_mask = (dec_in != pad_id).bool()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected batch length: {len(batch)}\")\n",
    "\n",
    "    enc_in = enc_in.to(device)\n",
    "    dec_in = dec_in.to(device)\n",
    "    tgt    = tgt.to(device)\n",
    "    enc_mask = enc_mask.to(device)\n",
    "    dec_mask = dec_mask.to(device)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # 모델 포워드 (마스크를 받는/안 받는 모델 모두 호환)\n",
    "    try:\n",
    "        logits = model(enc_in, dec_in, enc_mask=enc_mask, dec_mask=dec_mask)  # [B, L, V]\n",
    "    except TypeError:\n",
    "        logits = model(enc_in, dec_in)                                        # [B, L, V]\n",
    "\n",
    "    # CrossEntropyLoss는 [B, V, L] 형태를 기대 → permute\n",
    "    loss = loss_function(logits.permute(0, 2, 1), tgt)\n",
    "\n",
    "    loss.backward()\n",
    "    if grad_clip is not None:\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()   # LambdaLR(워밍업/역제곱루트)는 보통 배치마다 step\n",
    "\n",
    "    # 정확도 (PAD 제외)\n",
    "    with torch.no_grad():\n",
    "        preds = logits.argmax(dim=-1)           # [B, L]\n",
    "        mask  = (tgt != pad_id)\n",
    "        acc   = ((preds == tgt) & mask).sum().float() / mask.sum().clamp_min(1).float()\n",
    "\n",
    "    return loss.item(), acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b1b7db2-e098-42d3-a32f-843ae29b1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device, log_interval=100):\n",
    "    history = {\"loss\": [], \"acc\": []}\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        running_loss, running_acc, steps = 0.0, 0.0, 0\n",
    "        for step, batch in enumerate(dataloader, start=1):\n",
    "            loss, acc = train_step(\n",
    "                model=model,\n",
    "                batch=batch,\n",
    "                optimizer=optimizer,\n",
    "                loss_function=loss_function,\n",
    "                device=device,\n",
    "                scheduler=scheduler,   # 배치 스텝 스케줄러일 때만 효과\n",
    "            )\n",
    "            running_loss += loss\n",
    "            running_acc  += acc\n",
    "            steps += 1\n",
    "\n",
    "            if step % log_interval == 0:\n",
    "                print(f\"[Epoch {epoch:02d} | Step {step:04d}] loss={running_loss/steps:.4f} acc={running_acc/steps:.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / max(steps, 1)\n",
    "        epoch_acc  = running_acc  / max(steps, 1)\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        history[\"acc\"].append(epoch_acc)\n",
    "\n",
    "        print(f\"==> Epoch {epoch:02d} done | loss={epoch_loss:.4f} acc={epoch_acc:.4f}\")\n",
    "\n",
    "        # 에폭 단위 스케줄러를 쓰는 경우 여기에 scheduler.step() 배치\n",
    "        # if scheduler is not None and use_epoch_scheduler:\n",
    "        #     scheduler.step()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54a660be-c0b4-4135-a2a6-b7acc5c19085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01 | Step 0100] loss=8.5671 acc=0.1000\n",
      "[Epoch 01 | Step 0200] loss=7.7284 acc=0.1938\n",
      "[Epoch 01 | Step 0300] loss=7.2411 acc=0.2249\n",
      "==> Epoch 01 done | loss=7.0052 acc=0.2375\n",
      "[Epoch 02 | Step 0100] loss=5.7831 acc=0.2958\n",
      "[Epoch 02 | Step 0200] loss=5.7274 acc=0.2971\n",
      "[Epoch 02 | Step 0300] loss=5.6766 acc=0.2999\n",
      "==> Epoch 02 done | loss=5.6479 acc=0.3014\n",
      "[Epoch 03 | Step 0100] loss=5.2807 acc=0.3132\n",
      "[Epoch 03 | Step 0200] loss=5.2521 acc=0.3148\n",
      "[Epoch 03 | Step 0300] loss=5.2102 acc=0.3177\n",
      "==> Epoch 03 done | loss=5.1781 acc=0.3196\n",
      "[Epoch 04 | Step 0100] loss=4.7684 acc=0.3409\n",
      "[Epoch 04 | Step 0200] loss=4.7503 acc=0.3413\n",
      "[Epoch 04 | Step 0300] loss=4.7260 acc=0.3432\n",
      "==> Epoch 04 done | loss=4.7101 acc=0.3449\n",
      "[Epoch 05 | Step 0100] loss=4.2833 acc=0.3731\n",
      "[Epoch 05 | Step 0200] loss=4.2821 acc=0.3738\n",
      "[Epoch 05 | Step 0300] loss=4.2658 acc=0.3754\n",
      "==> Epoch 05 done | loss=4.2482 acc=0.3775\n",
      "[Epoch 06 | Step 0100] loss=3.8057 acc=0.4129\n",
      "[Epoch 06 | Step 0200] loss=3.7963 acc=0.4132\n",
      "[Epoch 06 | Step 0300] loss=3.7798 acc=0.4151\n",
      "==> Epoch 06 done | loss=3.7766 acc=0.4153\n",
      "[Epoch 07 | Step 0100] loss=3.2629 acc=0.4657\n",
      "[Epoch 07 | Step 0200] loss=3.2627 acc=0.4655\n",
      "[Epoch 07 | Step 0300] loss=3.2857 acc=0.4626\n",
      "==> Epoch 07 done | loss=3.2955 acc=0.4610\n",
      "[Epoch 08 | Step 0100] loss=2.7182 acc=0.5316\n",
      "[Epoch 08 | Step 0200] loss=2.7820 acc=0.5206\n",
      "[Epoch 08 | Step 0300] loss=2.8171 acc=0.5146\n",
      "==> Epoch 08 done | loss=2.8187 acc=0.5144\n",
      "[Epoch 09 | Step 0100] loss=2.2370 acc=0.5921\n",
      "[Epoch 09 | Step 0200] loss=2.3094 acc=0.5801\n",
      "[Epoch 09 | Step 0300] loss=2.3588 acc=0.5716\n",
      "==> Epoch 09 done | loss=2.3897 acc=0.5670\n",
      "[Epoch 10 | Step 0100] loss=1.8104 acc=0.6505\n",
      "[Epoch 10 | Step 0200] loss=1.8970 acc=0.6338\n",
      "[Epoch 10 | Step 0300] loss=1.9679 acc=0.6229\n",
      "==> Epoch 10 done | loss=2.0080 acc=0.6174\n",
      "[Epoch 11 | Step 0100] loss=1.4558 acc=0.7075\n",
      "[Epoch 11 | Step 0200] loss=1.5548 acc=0.6859\n",
      "[Epoch 11 | Step 0300] loss=1.6453 acc=0.6689\n",
      "==> Epoch 11 done | loss=1.6982 acc=0.6598\n",
      "[Epoch 12 | Step 0100] loss=1.1923 acc=0.7502\n",
      "[Epoch 12 | Step 0200] loss=1.2906 acc=0.7274\n",
      "[Epoch 12 | Step 0300] loss=1.3694 acc=0.7124\n",
      "==> Epoch 12 done | loss=1.4099 acc=0.7050\n",
      "[Epoch 13 | Step 0100] loss=0.9117 acc=0.8056\n",
      "[Epoch 13 | Step 0200] loss=1.0093 acc=0.7810\n",
      "[Epoch 13 | Step 0300] loss=1.0925 acc=0.7625\n",
      "==> Epoch 13 done | loss=1.1344 acc=0.7539\n",
      "[Epoch 14 | Step 0100] loss=0.7095 acc=0.8469\n",
      "[Epoch 14 | Step 0200] loss=0.7858 acc=0.8267\n",
      "[Epoch 14 | Step 0300] loss=0.8646 acc=0.8090\n",
      "==> Epoch 14 done | loss=0.9064 acc=0.7998\n",
      "[Epoch 15 | Step 0100] loss=0.5567 acc=0.8768\n",
      "[Epoch 15 | Step 0200] loss=0.6281 acc=0.8589\n",
      "[Epoch 15 | Step 0300] loss=0.6962 acc=0.8434\n",
      "==> Epoch 15 done | loss=0.7363 acc=0.8338\n",
      "[Epoch 16 | Step 0100] loss=0.4593 acc=0.9002\n",
      "[Epoch 16 | Step 0200] loss=0.5175 acc=0.8840\n",
      "[Epoch 16 | Step 0300] loss=0.5741 acc=0.8708\n",
      "==> Epoch 16 done | loss=0.6165 acc=0.8611\n",
      "[Epoch 17 | Step 0100] loss=0.3901 acc=0.9141\n",
      "[Epoch 17 | Step 0200] loss=0.4414 acc=0.9019\n",
      "[Epoch 17 | Step 0300] loss=0.4965 acc=0.8867\n",
      "==> Epoch 17 done | loss=0.5259 acc=0.8794\n",
      "[Epoch 18 | Step 0100] loss=0.3451 acc=0.9234\n",
      "[Epoch 18 | Step 0200] loss=0.3817 acc=0.9131\n",
      "[Epoch 18 | Step 0300] loss=0.4279 acc=0.9032\n",
      "==> Epoch 18 done | loss=0.4563 acc=0.8965\n",
      "[Epoch 19 | Step 0100] loss=0.3022 acc=0.9306\n",
      "[Epoch 19 | Step 0200] loss=0.3434 acc=0.9202\n",
      "[Epoch 19 | Step 0300] loss=0.3804 acc=0.9120\n",
      "==> Epoch 19 done | loss=0.4083 acc=0.9052\n",
      "[Epoch 20 | Step 0100] loss=0.2708 acc=0.9399\n",
      "[Epoch 20 | Step 0200] loss=0.3105 acc=0.9295\n",
      "[Epoch 20 | Step 0300] loss=0.3462 acc=0.9214\n",
      "==> Epoch 20 done | loss=0.3667 acc=0.9163\n",
      "[Epoch 21 | Step 0100] loss=0.2329 acc=0.9465\n",
      "[Epoch 21 | Step 0200] loss=0.2677 acc=0.9391\n",
      "[Epoch 21 | Step 0300] loss=0.3022 acc=0.9311\n",
      "==> Epoch 21 done | loss=0.3249 acc=0.9256\n",
      "[Epoch 22 | Step 0100] loss=0.2141 acc=0.9528\n",
      "[Epoch 22 | Step 0200] loss=0.2461 acc=0.9450\n",
      "[Epoch 22 | Step 0300] loss=0.2711 acc=0.9392\n",
      "==> Epoch 22 done | loss=0.2899 acc=0.9347\n",
      "[Epoch 23 | Step 0100] loss=0.1940 acc=0.9581\n",
      "[Epoch 23 | Step 0200] loss=0.2273 acc=0.9495\n",
      "[Epoch 23 | Step 0300] loss=0.2501 acc=0.9440\n",
      "==> Epoch 23 done | loss=0.2674 acc=0.9395\n",
      "[Epoch 24 | Step 0100] loss=0.1767 acc=0.9624\n",
      "[Epoch 24 | Step 0200] loss=0.2034 acc=0.9542\n",
      "[Epoch 24 | Step 0300] loss=0.2326 acc=0.9476\n",
      "==> Epoch 24 done | loss=0.2501 acc=0.9435\n",
      "[Epoch 25 | Step 0100] loss=0.1741 acc=0.9617\n",
      "[Epoch 25 | Step 0200] loss=0.1929 acc=0.9572\n",
      "[Epoch 25 | Step 0300] loss=0.2127 acc=0.9526\n",
      "==> Epoch 25 done | loss=0.2275 acc=0.9489\n",
      "CPU times: user 5min 50s, sys: 804 ms, total: 5min 50s\n",
      "Wall time: 3min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [7.005230533754504,\n",
       "  5.647927203049531,\n",
       "  5.178066586159371,\n",
       "  4.7101404860213,\n",
       "  4.24824151735048,\n",
       "  3.776612365568006,\n",
       "  3.2955406955770545,\n",
       "  2.8187331231864725,\n",
       "  2.3896736663741036,\n",
       "  2.0079982203406255,\n",
       "  1.6982167550035425,\n",
       "  1.4099263724443074,\n",
       "  1.1343701971543803,\n",
       "  0.9063537705588985,\n",
       "  0.7362560514662717,\n",
       "  0.6165401565062033,\n",
       "  0.5258983831550624,\n",
       "  0.45630706641319635,\n",
       "  0.40827760237294275,\n",
       "  0.36672150714171897,\n",
       "  0.3248966339069444,\n",
       "  0.28985243558480933,\n",
       "  0.2674026785267366,\n",
       "  0.250061173878006,\n",
       "  0.22745518098409112],\n",
       " 'acc': [0.2375271260889398,\n",
       "  0.3014477276721516,\n",
       "  0.3196065810081121,\n",
       "  0.3449239581017881,\n",
       "  0.3774856146122958,\n",
       "  0.4152763294207083,\n",
       "  0.46098750499454705,\n",
       "  0.5144065369625349,\n",
       "  0.5670267567441271,\n",
       "  0.617376780832136,\n",
       "  0.6598465144634247,\n",
       "  0.704981393105275,\n",
       "  0.7538909715575141,\n",
       "  0.7997530497409202,\n",
       "  0.833757744447605,\n",
       "  0.8610522255704209,\n",
       "  0.8794463924459509,\n",
       "  0.8964566599678349,\n",
       "  0.9052373011369963,\n",
       "  0.9163219179656055,\n",
       "  0.9256473531594147,\n",
       "  0.9346616869037215,\n",
       "  0.9394527478798016,\n",
       "  0.943509665534303,\n",
       "  0.9489498802133509]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=25,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41fa1ee-4fd9-4887-86f6-40271ff0bdcc",
   "metadata": {},
   "source": [
    "# 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baeb177b-4d93-467c-a0a3-9cc8d461053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "    # 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 인코더 입력: [START] + 인코딩 + [END]\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # 차원 확장: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 디코더 입력(dec_input)을 START_TOKEN만 포함한 상태로 시작\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # 모델 평가 모드\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 모델 forward: (enc_input, dec_input) -> (batch_size=1, seq_len, vocab_size)\n",
    "            logits = model(enc_input, dec_input)\n",
    "\n",
    "            # 마지막 타임스텝의 예측만 추출: shape (1, 1, vocab_size)\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # argmax로 가장 높은 확률의 토큰 선택\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # shape: (1,)\n",
    "\n",
    "            # 종료 토큰이면 중단\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # 디코더 입력(dec_input)에 예측 토큰을 이어붙임\n",
    "            predicted_id = predicted_id.unsqueeze(0)  # shape (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    # 최종 시퀀스: dec_input: (1, seq_len)에서 (seq_len,)로\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., 토큰들...]\n",
    "\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b12cf8bb-aa15-4a94-9332-d2ac8c416768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    # 디코더 인퍼런스 -> 예측된 토큰 시퀀스\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 토크나이저로 디코딩 (패딩, START/END 토큰 등은 제외하거나 처리)\n",
    "    # 여기서는 단순히 tokenizer.decode() 직접 호출\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a7c732f-79c4-41a9-9311-7cc91430c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨가 좋다.\n",
      "출력 : 헛헛하죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'헛헛하죠 .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '오늘 날씨가 좋다.'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "243e74b4-1a86-424c-bd42-cdfe02056123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 기분이 우울해\n",
      "출력 : 제가 음악드릴게요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'제가 음악드릴게요 .'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '나 기분이 우울해'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e48dc5-de10-42cd-8f47-ee7d8118902b",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- transformers의 구조를 감으로라도 이해하고, 코드를 볼 수 있었다. 아쉬운건 아직 코드가 익숙하지 않다.\n",
    "- 적은 데이터로도 이 정도 구현이 되는 것을 보니, 데이터가 많이 있다면 더 높은 성능을 기대할 수 있을 것 같다.\n",
    "- 지난 번에 데이터를 많이 살펴보지 않았는데, 이번에는 EDA를 충분히 하려고 노력한 점이 만족스럽다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce404d-7d85-4cde-b872-c2d99d7d95c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
